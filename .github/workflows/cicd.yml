name: Pokedex CI/CD Pipeline

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  FRONTEND_IMAGE_NAME: pokedex-frontend
  BACKEND_IMAGE_NAME: pokedex-backend
  DOCKER_REGISTRY: docker.io
  AWS_REGION: us-east-1

jobs:
  # 1. Test Application
  test:
    name: Test Application
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      # Frontend Tests
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install frontend dependencies
        run: |
          cd frontend
          npm ci

      - name: Run frontend linting
        run: |
          cd frontend
          npm run lint
        continue-on-error: true

      # Backend Tests
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install backend dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run backend tests
        run: |
          cd backend
          python manage.py test
        env:
          DEBUG: 'True'
          DB_HOST: 'localhost'
          DB_NAME: 'test_db'
          DB_USER: 'postgres'
          DB_PASS: 'postgres'
          SECRET_KEY: 'test-key-for-ci'

  # 2. Build Docker Images
  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      - name: Build and push frontend image
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          push: true
          tags:
            ${{ secrets.DOCKER_HUB_USERNAME }}/${{ env.FRONTEND_IMAGE_NAME
            }}:latest
          cache-from:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/${{
            env.FRONTEND_IMAGE_NAME }}:buildcache
          cache-to:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/${{
            env.FRONTEND_IMAGE_NAME }}:buildcache,mode=max

      - name: Build and push backend image
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          push: true
          tags:
            ${{ secrets.DOCKER_HUB_USERNAME }}/${{ env.BACKEND_IMAGE_NAME
            }}:latest
          cache-from:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/${{
            env.BACKEND_IMAGE_NAME }}:buildcache
          cache-to:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME }}/${{
            env.BACKEND_IMAGE_NAME }}:buildcache,mode=max

  # 3. Provision and Deploy
  deploy:
    name: Provision Infrastructure and Deploy
    needs: build
    runs-on: ubuntu-latest
    outputs:
      instance_ip: ${{ steps.get-ip.outputs.instance_ip }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.7

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/terraform-ec2
          chmod 600 ~/.ssh/terraform-ec2
          ssh-keygen -y -f ~/.ssh/terraform-ec2 > ~/.ssh/terraform-ec2.pub

      - name: Create terraform.tfvars file
        run: |
          cat > terraform.tfvars << EOF
          instance_type = "t2.micro"
          app_name = "pokedex-app"
          ssh_public_key = "$(cat ~/.ssh/terraform-ec2.pub)"
          EOF

      - name: Terraform Init
        run: terraform init

      # Clean up existing resources
      - name: Clean up existing Terraform resources
        run: |
          echo "Starting enhanced cleanup of Terraform resources..."

          # Create the enhanced cleanup script
          cat > cleanup.sh << 'EOF'
          #!/bin/bash
          set -e

          echo "=== ENHANCED TERRAFORM CLEANUP SCRIPT ==="

          # Get the app_name from terraform.tfvars or use default
          APP_NAME=$(grep -o 'app_name.*=.*".*"' terraform.tfvars | cut -d'"' -f2 || echo "pokedex-app")
          echo "Using app name: $APP_NAME"

          # Function to wait with timeout
          wait_with_timeout() {
            local timeout=$1
            local interval=$2
            local command=$3
            local message=$4
            
            echo "$message"
            
            local end_time=$(($(date +%s) + timeout))
            while [ $(date +%s) -lt $end_time ]; do
              if eval "$command"; then
                return 0
              fi
              echo "Still waiting... ($(($end_time - $(date +%s)))s remaining)"
              sleep $interval
            done
            
            echo "Timeout reached after ${timeout}s"
            return 1
          }

          # Step 1: Identify all resources to clean up
          echo "Identifying existing resources..."

          # Find security groups first (we'll need their IDs for other operations)
          echo "Finding security groups..."
          SG_IDS=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=$APP_NAME-sg" --query "SecurityGroups[].GroupId" --output text)
          if [ -z "$SG_IDS" ]; then
            echo "Also checking for security groups without proper naming..."
            SG_IDS=$(aws ec2 describe-security-groups --filters "Name=tag:Name,Values=$APP_NAME" --query "SecurityGroups[].GroupId" --output text)
          fi

          # Step 2: Find and terminate all EC2 instances
          echo "Finding EC2 instances..."
          # Check instances by security group first
          INSTANCE_IDS=""
          if [ -n "$SG_IDS" ]; then
            for SG_ID in $SG_IDS; do
              INSTANCES_BY_SG=$(aws ec2 describe-instances --filters "Name=instance.group-id,Values=$SG_ID" "Name=instance-state-name,Values=running,pending,stopping,stopped" --query "Reservations[].Instances[].InstanceId" --output text)
              if [ -n "$INSTANCES_BY_SG" ]; then
                INSTANCE_IDS="$INSTANCE_IDS $INSTANCES_BY_SG"
              fi
            done
          fi

          # Also check instances by tag name
          INSTANCES_BY_TAG=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=$APP_NAME" "Name=instance-state-name,Values=running,pending,stopping,stopped" --query "Reservations[].Instances[].InstanceId" --output text)
          if [ -n "$INSTANCES_BY_TAG" ]; then
            INSTANCE_IDS="$INSTANCE_IDS $INSTANCES_BY_TAG"
          fi

          # Deduplicate instance IDs
          INSTANCE_IDS=$(echo "$INSTANCE_IDS" | tr ' ' '\n' | sort | uniq | tr '\n' ' ')

          # Terminate instances
          if [ -n "$INSTANCE_IDS" ]; then
            echo "Found instances to terminate: $INSTANCE_IDS"
            aws ec2 terminate-instances --instance-ids $INSTANCE_IDS
            
            # Wait for instances to terminate
            echo "Waiting for instances to terminate..."
            for ID in $INSTANCE_IDS; do
              wait_with_timeout 300 10 "aws ec2 describe-instances --instance-ids $ID --query 'Reservations[].Instances[].State.Name' --output text | grep -q 'terminated'" "Waiting for instance $ID to terminate..."
            done
          else
            echo "No EC2 instances found to terminate"
          fi

          # Step 3: Release Elastic IPs
          echo "Releasing Elastic IPs..."
          ALLOCATION_IDS=$(aws ec2 describe-addresses --filters "Name=tag:Name,Values=$APP_NAME" --query "Addresses[].AllocationId" --output text || aws ec2 describe-addresses --query "Addresses[].AllocationId" --output text)
          if [ -n "$ALLOCATION_IDS" ]; then
            echo "Found Elastic IPs to release: $ALLOCATION_IDS"
            for ID in $ALLOCATION_IDS; do
              aws ec2 release-address --allocation-id $ID || echo "Failed to release Elastic IP $ID, may be already released or associated"
            done
          else
            echo "No Elastic IPs found"
          fi

          # Step 4: Detach and delete network interfaces
          echo "Checking for network interfaces..."
          if [ -n "$SG_IDS" ]; then
            for SG_ID in $SG_IDS; do
              ENI_IDS=$(aws ec2 describe-network-interfaces --filters "Name=group-id,Values=$SG_ID" --query "NetworkInterfaces[].NetworkInterfaceId" --output text)
              if [ -n "$ENI_IDS" ]; then
                echo "Found network interfaces using security group $SG_ID: $ENI_IDS"
                for ENI_ID in $ENI_IDS; do
                  # Check if the interface is attached
                  ATTACHMENT_ID=$(aws ec2 describe-network-interfaces --network-interface-ids $ENI_ID --query "NetworkInterfaces[].Attachment.AttachmentId" --output text)
                  if [ -n "$ATTACHMENT_ID" ] && [ "$ATTACHMENT_ID" != "None" ]; then
                    echo "Detaching network interface $ENI_ID (attachment $ATTACHMENT_ID)..."
                    aws ec2 detach-network-interface --attachment-id $ATTACHMENT_ID --force
                    
                    # Wait for detachment to complete
                    wait_with_timeout 60 5 "aws ec2 describe-network-interfaces --network-interface-ids $ENI_ID --query 'NetworkInterfaces[].Status' --output text | grep -q 'available'" "Waiting for network interface $ENI_ID to detach..."
                  fi
                  
                  # Delete the network interface
                  echo "Deleting network interface $ENI_ID..."
                  aws ec2 delete-network-interface --network-interface-id $ENI_ID || echo "Failed to delete network interface $ENI_ID"
                done
              else
                echo "No network interfaces found for security group $SG_ID"
              fi
            done
          fi

          # Step 5: Delete security groups with retry logic
          if [ -n "$SG_IDS" ]; then
            echo "Deleting security groups: $SG_IDS"
            for SG_ID in $SG_IDS; do
              echo "Processing security group $SG_ID..."
              
              # First revoke all ingress and egress rules
              echo "Revoking ingress rules for $SG_ID..."
              INGRESS_PERMISSIONS=$(aws ec2 describe-security-groups --group-ids $SG_ID --query "SecurityGroups[0].IpPermissions" --output json)
              if [ "$INGRESS_PERMISSIONS" != "[]" ] && [ "$INGRESS_PERMISSIONS" != "null" ]; then
                aws ec2 revoke-security-group-ingress --group-id $SG_ID --ip-permissions "$INGRESS_PERMISSIONS" || echo "No ingress rules to revoke or failed to revoke"
              fi
              
              echo "Revoking egress rules for $SG_ID..."
              EGRESS_PERMISSIONS=$(aws ec2 describe-security-groups --group-ids $SG_ID --query "SecurityGroups[0].IpPermissionsEgress" --output json)
              if [ "$EGRESS_PERMISSIONS" != "[]" ] && [ "$EGRESS_PERMISSIONS" != "null" ]; then
                aws ec2 revoke-security-group-egress --group-id $SG_ID --ip-permissions "$EGRESS_PERMISSIONS" || echo "No egress rules to revoke or failed to revoke"
              fi
              
              # Now try to delete with retries
              MAX_RETRIES=5
              for ((i=1; i<=MAX_RETRIES; i++)); do
                echo "Attempt $i to delete security group $SG_ID..."
                if aws ec2 delete-security-group --group-id $SG_ID; then
                  echo "Successfully deleted security group $SG_ID"
                  break
                else
                  if [ $i -eq $MAX_RETRIES ]; then
                    echo "Failed to delete security group $SG_ID after $MAX_RETRIES attempts"
                  else
                    echo "Deletion failed, waiting before retry..."
                    sleep 15
                  fi
                fi
              done
            done
          else
            echo "No security groups found"
          fi

          # Step 6: Delete key pairs
          echo "Deleting key pairs..."
          KEY_PAIRS=$(aws ec2 describe-key-pairs --filters "Name=key-name,Values=$APP_NAME-key" --query "KeyPairs[].KeyName" --output text)
          if [ -n "$KEY_PAIRS" ]; then
            echo "Found key pairs to delete: $KEY_PAIRS"
            for KEY in $KEY_PAIRS; do
              aws ec2 delete-key-pair --key-name $KEY
            done
          else
            echo "No key pairs found"
          fi

          echo "Resource cleanup completed successfully!"
          EOF
              
              # Make the script executable
              chmod +x cleanup.sh
              
              # Run the cleanup script
              ./cleanup.sh || {
                echo "Cleanup script encountered errors, but we will continue with deployment"
                # Don't fail the pipeline if cleanup has issues
              }
              
              echo "Cleanup process completed."
      - name: Terraform Apply
        run: terraform apply -auto-approve

      - name: Get Instance IP
        id: get-ip
        run: |
          # Get the raw outputs and clean them up
          INSTANCE_ID=$(terraform output -raw instance_id | grep -oE '[a-zA-Z0-9_-]+' | head -1)
          IP_ADDRESS=$(terraform output -raw instance_public_ip | grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | head -1)

          # Set the outputs properly
          echo "instance_ip=${IP_ADDRESS}" >> $GITHUB_OUTPUT
          echo "INSTANCE_IP=${IP_ADDRESS}" >> $GITHUB_ENV

          # Debug what we're setting
          echo "Found instance IP: ${IP_ADDRESS}"

      - name: Wait for instance to initialize
        run: |
          echo "Waiting for instance to initialize..."
          sleep 60

      - name: Copy configuration files
        run: |
          # Create directory structure first
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$INSTANCE_IP "mkdir -p ~/pokedex-app"

          # Then copy files
          scp -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ./docker-compose.yml ubuntu@$INSTANCE_IP:~/pokedex-app/

          # Copy nginx.conf to the server if it exists
          scp -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ./frontend/nginx.conf ubuntu@$INSTANCE_IP:~/pokedex-app/ || echo "nginx.conf not found, skipping"

      - name: Deploy with Docker Compose
        run: |
          # Create a simplified deployment script
          cat > deploy-docker.sh << 'EOF'
          #!/bin/bash
          set -e  # Exit on any error

          echo "========== DOCKER DEPLOYMENT START =========="
          echo "Running as user: $(whoami)"

          # Create app directory
          mkdir -p ~/pokedex-app
          cd ~/pokedex-app
          echo "Working directory: $(pwd)"

          # Get server IP
          SERVER_IP=$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4)
          echo "Server IP: $SERVER_IP"

          # Function to wait for apt to be available
          wait_for_apt() {
            echo "Waiting for apt to be available..."
            # Wait for any running apt processes to finish
            while ps aux | grep -i apt | grep -v grep > /dev/null; do
              echo "Apt process is running. Waiting..."
              sleep 10
            done
            
            # Remove lock files if they exist
            sudo rm -f /var/lib/apt/lists/lock
            sudo rm -f /var/lib/dpkg/lock
            sudo rm -f /var/lib/dpkg/lock-frontend
            sudo rm -f /var/cache/apt/archives/lock
            
            echo "Apt should be available now"
          }

          # Install Docker using snap instead of apt
          install_docker() {
            echo "Installing Docker using snap..."
            sudo snap install docker
            
            # Add current user to docker group
            sudo addgroup --system docker || true
            sudo adduser $USER docker || true
            
            # Wait for snap installation to complete
            sleep 10
            
            # Verify Docker installation
            which docker || echo "Docker binary not found in PATH"
            sudo docker --version || echo "Docker command failed"
          }

          # If Docker is not installed, install it
          if ! command -v docker &> /dev/null; then
            wait_for_apt
            install_docker
          else
            echo "Docker is already installed: $(docker --version)"
          fi

          # Set up docker-compose
          echo "Setting up docker-compose..."
          if ! command -v docker-compose &> /dev/null; then
            # Create docker-compose wrapper script
            sudo tee /usr/local/bin/docker-compose > /dev/null << 'DCSCRIPT'
          #!/bin/bash
          sudo docker compose "$@"
          DCSCRIPT
            sudo chmod +x /usr/local/bin/docker-compose
          fi

          # Create environment file
          echo "Creating .env file..."
          cat > .env << ENVFILE
          DB_USER=$DB_USER
          DB_PASS=$DB_PASS
          DB_NAME=$DB_NAME
          API_URL=http://${SERVER_IP}:3000
          DJANGO_SECRET_KEY=$DJANGO_SECRET_KEY
          NODE_ENV=production
          DOCKER_HUB_USERNAME=$DOCKER_USERNAME
          ENVFILE

          echo "Contents of .env file:"
          cat .env

          # Create docker-compose.yml file
          echo "Creating docker-compose.yml..."
          cat > docker-compose.yml << DCFILE
          version: '3'

          services:
            frontend:
              image: ${DOCKER_USERNAME}/${FRONTEND_IMAGE_NAME}:latest
              restart: always
              ports:
                - "80:80"
              depends_on:
                - backend

            backend:
              image: ${DOCKER_USERNAME}/${BACKEND_IMAGE_NAME}:latest
              restart: always
              ports:
                - "3000:3000"
              depends_on:
                - db
              environment:
                - DB_HOST=db
                - DB_USER=${DB_USER}
                - DB_PASS=${DB_PASS}
                - DB_NAME=${DB_NAME}
                - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}

            db:
              image: postgres:14
              restart: always
              volumes:
                - postgres_data:/var/lib/postgresql/data
              environment:
                - POSTGRES_USER=${DB_USER}
                - POSTGRES_PASSWORD=${DB_PASS}
                - POSTGRES_DB=${DB_NAME}

          volumes:
            postgres_data:
          DCFILE

          echo "Contents of docker-compose.yml:"
          cat docker-compose.yml

          # Login to Docker Hub
          echo "Logging into Docker Hub..."
          echo "$DOCKER_TOKEN" | sudo docker login -u "$DOCKER_USERNAME" --password-stdin

          # Stop any existing containers
          echo "Stopping any existing containers..."
          sudo docker-compose down || true

          # Pull images directly (bypass docker-compose pull)
          echo "Pulling images..."
          sudo docker pull ${DOCKER_USERNAME}/${FRONTEND_IMAGE_NAME}:latest || {
            echo "Failed to pull frontend image. Checking Docker Hub login status..."
            sudo docker login --username "$DOCKER_USERNAME"
          }
          sudo docker pull ${DOCKER_USERNAME}/${BACKEND_IMAGE_NAME}:latest
          sudo docker pull postgres:14

          # Start containers
          echo "Starting containers..."
          sudo docker-compose up -d --force-recreate

          # Check if containers are running
          echo "Checking containers status:"
          sudo docker ps -a

          # Check services
          echo "Checking if services are running:"
          sleep 10  # Give containers time to start
          curl -s -I http://localhost:80 || echo "Frontend not accessible yet"
          curl -s -I http://localhost:3000 || echo "Backend not accessible yet"

          echo "========== DOCKER DEPLOYMENT END =========="
          EOF

          # Make script executable
          chmod +x deploy-docker.sh

          # Copy script to server
          scp -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ./deploy-docker.sh ubuntu@$INSTANCE_IP:~/deploy-docker.sh

          # Execute script with environment variables
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$INSTANCE_IP "\
          FRONTEND_IMAGE_NAME='${{ env.FRONTEND_IMAGE_NAME }}' \
          BACKEND_IMAGE_NAME='${{ env.BACKEND_IMAGE_NAME }}' \
          DOCKER_USERNAME='${{ secrets.DOCKER_HUB_USERNAME }}' \
          DOCKER_TOKEN='${{ secrets.DOCKER_HUB_TOKEN }}' \
          DB_USER='${{ secrets.DB_USER || 'admin' }}' \
          DB_PASS='${{ secrets.DB_PASS || 'your_db_password' }}' \
          DB_NAME='${{ secrets.DB_NAME || 'pokedex_db' }}' \
          DJANGO_SECRET_KEY='${{ secrets.DJANGO_SECRET_KEY || 'django-insecure-key' }}' \
          bash ~/deploy-docker.sh"

          # Verify deployment
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$INSTANCE_IP "echo 'Final status:' && sudo docker ps && echo 'Service ports:' && sudo ss -tulpn | grep -E ':(80|3000)'"

  # 4. Health Check
  health-check:
    name: Health Check
    needs: deploy
    runs-on: ubuntu-latest
    steps:
      - name: Check application availability
        run: |
          INSTANCE_IP="${{ needs.deploy.outputs.instance_ip }}"

          echo "Waiting for services to fully start..."
          sleep 30

          echo "Checking frontend at http://$INSTANCE_IP"
          curl -s -f -m 10 -L "http://$INSTANCE_IP" || echo "Frontend not available yet"

          echo "Checking backend API at http://$INSTANCE_IP:3000/admin/"
          curl -s -f -m 10 "http://$INSTANCE_IP:3000/admin/" || echo "Backend API not available yet"

          echo "Application URLs:"
          echo "Frontend: http://$INSTANCE_IP"
          echo "Backend API: http://$INSTANCE_IP:3000"
