name: Pokedex CI/CD Pipeline

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  FRONTEND_IMAGE_NAME: pokedex-frontend
  BACKEND_IMAGE_NAME: pokedex-backend
  DOCKER_REGISTRY: docker.io
  AWS_REGION: us-east-1
  SSH_KEY_PATH: ~/.ssh/terraform-ec2

jobs:
  # 0. Prepare SSH Keys
  prepare:
    name: Prepare SSH Keys
    runs-on: ubuntu-latest
    steps:
      - name: Setup SSH key for debugging
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ${{ env.SSH_KEY_PATH }}
          chmod 600 ${{ env.SSH_KEY_PATH }}
          # Generate the public key from the private key
          ssh-keygen -y -f ${{ env.SSH_KEY_PATH }} > ${{ env.SSH_KEY_PATH }}.pub

          # Debug output - show key fingerprints (safe to display)
          echo "Private key fingerprint:"
          ssh-keygen -l -f ${{ env.SSH_KEY_PATH }}

          echo "Public key fingerprint:"
          ssh-keygen -l -f ${{ env.SSH_KEY_PATH }}.pub

          # Check key format - show first and last line only (safe to display)
          echo "Private key format check (first line):"
          head -n 1 ${{ env.SSH_KEY_PATH }}

          echo "Private key format check (last line):"
          tail -n 1 ${{ env.SSH_KEY_PATH }}

          # Verify public key format
          echo "Public key content:"
          cat ${{ env.SSH_KEY_PATH }}.pub

          echo "SSH key created successfully at ${{ env.SSH_KEY_PATH }}"

  # 1. Test and Analyze  Code
  test:
    name: Test Application
    runs-on: ubuntu-latest
    needs: prepare

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      # Frontend Tests
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install frontend dependencies
        run: |
          cd frontend
          npm ci

      - name: Run frontend linting
        run: |
          cd frontend
          npm run lint
        continue-on-error: true

      # Backend Tests
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install backend dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run backend tests
        run: |
          cd backend
          python manage.py test
        env:
          DEBUG: 'True'
          DB_HOST: 'localhost'
          DB_NAME: 'test_db'
          DB_USER: 'postgres'
          DB_PASS: 'postgres'
          SECRET_KEY: 'test-key-for-ci'

  # 2. Build Docker Images
  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to DockerHub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      - name: Build and push frontend image
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          push: true
          tags: ${{ secrets.DOCKER_HUB_USERNAME }}/pokedex-frontend:latest
          cache-from:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-frontend:buildcache
          cache-to:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-frontend:buildcache,mode=max

      - name: Build and push backend image
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          push: true
          tags: ${{ secrets.DOCKER_HUB_USERNAME }}/pokedex-backend:latest
          cache-from:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-backend:buildcache
          cache-to:
            type=registry,ref=${{ secrets.DOCKER_HUB_USERNAME
            }}/pokedex-backend:buildcache,mode=max

  # 3. Provision Infrastructure with Terraform
  provision-infrastructure:
    name: Provision Infrastructure
    needs: [prepare, build]
    runs-on: ubuntu-latest
    outputs:
      instance_ip: ${{ steps.extract-ip.outputs.instance_public_ip }}
      instance_id: ${{ steps.extract-instance-id.outputs.instance_id }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Test AWS Credentials
        run: |
          echo "Validating AWS credentials and permissions..."

          # Get caller identity
          aws sts get-caller-identity

          # Check if we can list EC2 instances
          echo "Checking EC2 permissions..."
          aws ec2 describe-instances --region ${{ env.AWS_REGION }} --max-items 5

          # Check current EC2 quotas/limits
          echo "Checking EC2 service quotas..."
          aws service-quotas get-service-quota --service-code ec2 --quota-code L-1216C47A --region ${{ env.AWS_REGION }} || echo "Could not get quota info, but continuing"

          # Check if VPC exists
          echo "Checking default VPC..."
          aws ec2 describe-vpcs --filters "Name=isDefault,Values=true" --region ${{ env.AWS_REGION }}

          # List available subnets in default VPC
          echo "Listing available subnets..."
          DEFAULT_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=isDefault,Values=true" --query "Vpcs[0].VpcId" --output text --region ${{ env.AWS_REGION }})
          aws ec2 describe-subnets --filters "Name=vpc-id,Values=$DEFAULT_VPC_ID" --region ${{ env.AWS_REGION }}

          echo "AWS region being used: ${{ env.AWS_REGION }}"
          aws ec2 describe-regions --output json | jq -r '.Regions[0].RegionName' || echo "Region listing failed"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.7

      - name: Setup SSH key for Terraform
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ${{ env.SSH_KEY_PATH }}
          chmod 600 ${{ env.SSH_KEY_PATH }}
          ssh-keygen -y -f ${{ env.SSH_KEY_PATH }} > ${{ env.SSH_KEY_PATH }}.pub
          echo "Public key for EC2:"
          cat ${{ env.SSH_KEY_PATH }}.pub

      # Clean slate approach - delete all resources with same names first
      - name: Clean up existing resources
        run: |
          # Delete any instance with the tag Name=pokedex-app-server
          INSTANCE_IDS=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[*].Instances[*].InstanceId" --output text --region ${{ env.AWS_REGION }})
          if [ ! -z "$INSTANCE_IDS" ]; then
            echo "Terminating instances: $INSTANCE_IDS"
            aws ec2 terminate-instances --instance-ids $INSTANCE_IDS --region ${{ env.AWS_REGION }}
            echo "Waiting for instances to terminate..."
            aws ec2 wait instance-terminated --instance-ids $INSTANCE_IDS --region ${{ env.AWS_REGION }}
          fi

          # Delete the key pair if it exists
          aws ec2 delete-key-pair --key-name pokedex-app-key --region ${{ env.AWS_REGION }} || true

          # Force delete security group
          SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=pokedex-app-sg" --query "SecurityGroups[0].GroupId" --output text --region ${{ env.AWS_REGION }} || echo "")
          if [ "$SG_ID" != "None" ] && [ "$SG_ID" != "" ]; then
            echo "Force deleting security group $SG_ID and its dependencies..."
            # Delete any EIPs associated with instances using this SG
            EIP_ALLOC_IDS=$(aws ec2 describe-network-interfaces --filters "Name=group-id,Values=$SG_ID" --query "NetworkInterfaces[*].Association.AllocationId" --output text --region ${{ env.AWS_REGION }} || echo "")
            for ALLOC_ID in $EIP_ALLOC_IDS; do
              [ ! -z "$ALLOC_ID" ] && aws ec2 release-address --allocation-id $ALLOC_ID --region ${{ env.AWS_REGION }} || true
            done
            
            # Delete any network interfaces using this SG
            INTERFACE_IDS=$(aws ec2 describe-network-interfaces --filters "Name=group-id,Values=$SG_ID" --query "NetworkInterfaces[*].NetworkInterfaceId" --output text --region ${{ env.AWS_REGION }} || echo "")
            for INTERFACE_ID in $INTERFACE_IDS; do
              [ ! -z "$INTERFACE_ID" ] && aws ec2 delete-network-interface --network-interface-id $INTERFACE_ID --region ${{ env.AWS_REGION }} || true
            done
            
            sleep 10
            aws ec2 delete-security-group --group-id $SG_ID --region ${{ env.AWS_REGION }} || true
          fi

      - name: Create terraform.tfvars file
        run: |
          cat > terraform.tfvars << EOF
          instance_type = "t2.micro"
          app_name = "pokedex-app"
          ssh_public_key = "$(cat ${{ env.SSH_KEY_PATH }}.pub)"
          EOF

          echo "terraform.tfvars contents:"
          cat terraform.tfvars

      - name: Terraform Init
        run: terraform init

      - name: Terraform Apply Directly
        run: |
          # Set Terraform to verbose logging
          export TF_LOG=DEBUG

          # Apply and capture all output for debugging
          terraform apply -auto-approve 2>&1 | tee terraform-apply.log

          # Check Terraform state for instance after apply
          echo "Checking Terraform state after apply..."
          terraform state show aws_instance.app_server || echo "Could not find instance in Terraform state"

          # Check AWS directly to see if instance exists
          echo "Checking AWS directly for instance..."
          aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[*].Instances[*].[InstanceId,State.Name]" --output table --region ${{ env.AWS_REGION }}

      - name: Extract IP from AWS
        id: extract-ip
        run: |
          # Debug instance state first
          echo "Checking for instances with tag pokedex-app-server..."
          aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[*].Instances[*].[InstanceId,State.Name]" --output table --region ${{ env.AWS_REGION }}

          # Extract instance ID using AWS CLI
          INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[0].Instances[0].InstanceId" --output text --region ${{ env.AWS_REGION }})
          echo "Found Instance ID: ${INSTANCE_ID}"

          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" == "None" ]; then
            echo "ERROR: No instance found with tag Name=pokedex-app-server"
            exit 1
          fi

          # Check instance state explicitly
          INSTANCE_STATE=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query "Reservations[0].Instances[0].State.Name" --output text --region ${{ env.AWS_REGION }})
          echo "Instance state: $INSTANCE_STATE"

          if [ "$INSTANCE_STATE" != "running" ]; then
            echo "WARNING: Instance is not in running state. Current state: $INSTANCE_STATE"
            
            # Check console output for debugging
            echo "Getting console output for debugging..."
            aws ec2 get-console-output --instance-id $INSTANCE_ID --region ${{ env.AWS_REGION }} || echo "Unable to get console output"
            
            if [ "$INSTANCE_STATE" == "terminated" ]; then
              echo "ERROR: Instance was terminated. Checking termination reason..."
              aws ec2 describe-instances --instance-ids $INSTANCE_ID --query "Reservations[0].Instances[0].StateReason" --output json --region ${{ env.AWS_REGION }}
              exit 1
            fi
          fi

          # Only wait if instance is pending
          if [ "$INSTANCE_STATE" == "pending" ]; then
            # Wait for instance to be running
            echo "Waiting for instance $INSTANCE_ID to be in running state..."
            aws ec2 wait instance-running --instance-ids $INSTANCE_ID --region ${{ env.AWS_REGION }}
          fi

          # First try to get the Elastic IP (more reliable)
          IP_ADDRESS=$(aws ec2 describe-addresses --filters "Name=instance-id,Values=${INSTANCE_ID}" --query "Addresses[0].PublicIp" --output text --region ${{ env.AWS_REGION }})

          # If Elastic IP not found, try to get regular public IP
          if [ -z "$IP_ADDRESS" ] || [ "$IP_ADDRESS" == "None" ]; then
            IP_ADDRESS=$(aws ec2 describe-instances --instance-ids "${INSTANCE_ID}" --query "Reservations[0].Instances[0].PublicIpAddress" --output text --region ${{ env.AWS_REGION }})
          fi

          echo "Found IP Address: ${IP_ADDRESS}"
          echo "instance_public_ip=${IP_ADDRESS}" >> $GITHUB_OUTPUT
          # Also set as an environment variable for other steps
          echo "INSTANCE_PUBLIC_IP=${IP_ADDRESS}" >> $GITHUB_ENV

      - name: Extract Instance ID from AWS
        id: extract-instance-id
        run: |
          # Extract instance ID using AWS CLI to be more reliable
          INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[0].Instances[0].InstanceId" --output text --region ${{ env.AWS_REGION }})
          echo "Found Instance ID: ${INSTANCE_ID}"
          echo "instance_id=${INSTANCE_ID}" >> $GITHUB_OUTPUT
          # Also set as an environment variable for other steps
          echo "INSTANCE_ID=${INSTANCE_ID}" >> $GITHUB_ENV

      - name: Wait for instance initialization
        run: |
          echo "Waiting 2 minutes for instance to initialize..."
          sleep 120
          echo "Wait complete, proceeding to next steps."

          # Print the values being passed to the next steps for debugging
          echo "Instance ID being passed: ${{ steps.extract-instance-id.outputs.instance_id }}"
          echo "Instance IP being passed: ${{ steps.extract-ip.outputs.instance_public_ip }}"

  # 4. Deploy Application
  deploy-application:
    name: Deploy Application
    needs: [prepare, provision-infrastructure]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get instance details directly
        run: |
          # Get instance ID directly from AWS
          INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[0].Instances[0].InstanceId" --output text --region ${{ env.AWS_REGION }})
          echo "Direct Instance ID: $INSTANCE_ID"

          # First try to get Elastic IP
          IP_ADDRESS=$(aws ec2 describe-addresses --filters "Name=instance-id,Values=${INSTANCE_ID}" --query "Addresses[0].PublicIp" --output text --region ${{ env.AWS_REGION }})

          # If no Elastic IP, try to get public IP
          if [ -z "$IP_ADDRESS" ] || [ "$IP_ADDRESS" == "None" ]; then
            IP_ADDRESS=$(aws ec2 describe-instances --instance-ids "${INSTANCE_ID}" --query "Reservations[0].Instances[0].PublicIpAddress" --output text --region ${{ env.AWS_REGION }})
          fi

          echo "Direct IP Address: $IP_ADDRESS"

          # Set as environment variables for later steps
          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_ENV
          echo "INSTANCE_IP=$IP_ADDRESS" >> $GITHUB_ENV

      # Set up direct SSH connection (more reliable than ssh-agent)
      - name: Setup SSH connection with direct IP
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/terraform-ec2
          chmod 600 ~/.ssh/terraform-ec2

          # Use the IP from environment variable
          IP="${INSTANCE_IP}"
          echo "Using IP address: $IP"

          if [ -z "$IP" ] || [ "$IP" == "None" ]; then
            echo "Error: Failed to determine instance IP address"
            exit 1
          fi

          # Save for later steps
          echo "$IP" > ~/.ssh/instance_ip

          # Basic connectivity check
          echo "Testing basic network connectivity..."
          ping -c 2 $IP || echo "Ping failed but continuing"

          # Configure SSH for direct IP usage
          ssh-keyscan -H $IP >> ~/.ssh/known_hosts 2>/dev/null || echo "ssh-keyscan failed but continuing"

          # Test SSH connection directly - retry logic
          echo "Testing SSH connection..."
          max_attempts=5
          attempt=1
          connected=false

          while [ $attempt -le $max_attempts ] && [ "$connected" != "true" ]; do
            echo "SSH connection attempt $attempt of $max_attempts..."
            
            if ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@$IP 'echo "SSH connection successful"'; then
              connected=true
              echo "SSH connection established!"
            else
              echo "Connection attempt failed, waiting before retry..."
              sleep 20
              attempt=$((attempt+1))
            fi
          done

          if [ "$connected" != "true" ]; then
            echo "Failed to establish SSH connection after $max_attempts attempts."
            exit 1
          fi

      - name: Wait for SSH to be available
        run: |
          IP=$(cat ~/.ssh/instance_ip)
          echo "Waiting for system services to be fully ready..."

          # Wait for cloud-init to complete
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP "cloud-init status --wait || echo 'cloud-init wait failed but continuing'"

          # Additional wait to ensure Docker is properly initialized
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP "timeout 60 bash -c 'until docker info; do sleep 5; done' || echo 'Docker not ready, but continuing'"

      - name: Create deployment directory
        run: |
          IP=$(cat ~/.ssh/instance_ip)
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP 'mkdir -p ~/pokedex-app'

      - name: Copy configuration files
        run: |
          IP=$(cat ~/.ssh/instance_ip)
          # Use explicit paths based on your repository structure
          echo "Copying docker-compose.yml from repository root"
          scp -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ./docker-compose.yml ubuntu@$IP:~/pokedex-app/

          echo "Copying nginx.conf from frontend directory"
          scp -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ./frontend/nginx.conf ubuntu@$IP:~/pokedex-app/ || echo "nginx.conf not found, skipping"

      - name: Deploy with Docker Compose
        run: |
          IP=$(cat ~/.ssh/instance_ip)
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP << 'ENDSSH'
            cd ~/pokedex-app
            
            # Create a clean .env file directly on the server
            cat > .env << EOF
            DB_USER=${{ secrets.DB_USER }}
            DB_PASS=${{ secrets.DB_PASS }}
            DB_NAME=${{ secrets.DB_NAME }}
            API_URL=http://$IP:3000
            DJANGO_SECRET_KEY=${{ secrets.DJANGO_SECRET_KEY }}
            NODE_ENV=production
            DOCKER_HUB_USERNAME=${{ secrets.DOCKER_HUB_USERNAME }}
            EOF
            
            # Copy the updated nginx.conf
            cat > nginx.conf << 'EOF'
            server {
                listen 80;
                server_name localhost;
                root /usr/share/nginx/html;
                index index.html;
            
                # Disable any automatic HTTPS redirects
                absolute_redirect off;
            
                # Gzip compression
                gzip on;
                gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
                
                # Handle Single Page Application routing
                location / {
                    try_files $uri $uri/ /index.html;
                    
                    # Explicitly prevent any HTTP to HTTPS redirects
                    proxy_redirect off;
                    
                    # Add Cross-Origin headers
                    add_header 'Access-Control-Allow-Origin' '*';
                    add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
                    add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range';
                }
            
                # API proxy configuration
                location /api/ {
                    proxy_pass http://backend:3000/;
                    proxy_http_version 1.1;
                    proxy_set_header Upgrade $http_upgrade;
                    proxy_set_header Connection 'upgrade';
                    proxy_set_header Host $host;
                    proxy_cache_bypass $http_upgrade;
                }
            
                # Cache static assets
                location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
                    expires 1d;
                    add_header Cache-Control "public";
                }
            
                # Error handling
                error_page 404 /index.html;
                error_page 500 502 503 504 /50x.html;
                location = /50x.html {
                    root /usr/share/nginx/html;
                }
            }
            EOF
            
            # Make sure Docker is running
            sudo systemctl start docker
            sudo systemctl enable docker
            
            # Stop any running containers
            sudo docker-compose down
            
            # Pull the latest images
            sudo docker-compose pull
            
            # Start the application
            sudo docker-compose up -d
            
            # Print container status
            sudo docker-compose ps
            
            # Check container logs (last 20 lines each)
            echo "Frontend logs:"
            sudo docker-compose logs --tail=20 frontend
            
            echo "Backend logs:"
            sudo docker-compose logs --tail=20 backend
            
            echo "Database logs:"
            sudo docker-compose logs --tail=20 db
          ENDSSH

  # 5. Health Check and Monitoring
  health-check:
    name: Health Check and Monitoring
    needs: [provision-infrastructure, deploy-application]
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get instance IP directly
        run: |
          # Get instance ID directly from AWS
          INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[0].Instances[0].InstanceId" --output text --region ${{ env.AWS_REGION }})

          # First try to get Elastic IP
          IP_ADDRESS=$(aws ec2 describe-addresses --filters "Name=instance-id,Values=${INSTANCE_ID}" --query "Addresses[0].PublicIp" --output text --region ${{ env.AWS_REGION }})

          # If no Elastic IP, try to get public IP
          if [ -z "$IP_ADDRESS" ] || [ "$IP_ADDRESS" == "None" ]; then
            IP_ADDRESS=$(aws ec2 describe-instances --instance-ids "${INSTANCE_ID}" --query "Reservations[0].Instances[0].PublicIpAddress" --output text --region ${{ env.AWS_REGION }})
          fi

          echo "Using IP address: $IP_ADDRESS"
          echo "INSTANCE_IP=$IP_ADDRESS" >> $GITHUB_ENV

      - name: Setup SSH connection for monitoring
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/terraform-ec2
          chmod 600 ~/.ssh/terraform-ec2

          # Get the IP directly from AWS again to ensure we have it
          INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=pokedex-app-server" --query "Reservations[0].Instances[0].InstanceId" --output text --region ${{ env.AWS_REGION }})

          # Get IP address (try Elastic IP first, then public IP)
          IP_ADDRESS=$(aws ec2 describe-addresses --filters "Name=instance-id,Values=${INSTANCE_ID}" --query "Addresses[0].PublicIp" --output text --region ${{ env.AWS_REGION }})
          if [ -z "$IP_ADDRESS" ] || [ "$IP_ADDRESS" == "None" ]; then
            IP_ADDRESS=$(aws ec2 describe-instances --instance-ids "${INSTANCE_ID}" --query "Reservations[0].Instances[0].PublicIpAddress" --output text --region ${{ env.AWS_REGION }})
          fi

          echo "Using IP address: $IP_ADDRESS"

          # Store IP in a file for later steps
          echo "$IP_ADDRESS" > ~/.ssh/instance_ip

          # Add to known hosts if possible
          ssh-keyscan -H $IP_ADDRESS >> ~/.ssh/known_hosts 2>/dev/null || echo "ssh-keyscan failed but continuing"

      - name: Wait for services to start
        run: |
          echo "Waiting for services to fully start (30 seconds)..."
          sleep 30

      - name: Check frontend availability
        id: frontend-health
        run: |
          # Get IP address from file
          IP_ADDRESS=$(cat ~/.ssh/instance_ip)

          echo "Checking frontend at http://$IP_ADDRESS"
          MAX_ATTEMPTS=10
          ATTEMPT=1

          # First check if the server itself can access the frontend
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP_ADDRESS << 'ENDSSH'
            echo "Checking frontend locally from server:"
            curl -v http://localhost:80
            
            echo "Checking if Docker containers are running:"
            sudo docker ps
            
            echo "Checking Docker networks:"
            sudo docker network ls
            
            echo "Getting container IPs:"
            for CONTAINER_ID in $(sudo docker ps -q); do
              echo "Container: $(sudo docker inspect --format '{{.Name}}' $CONTAINER_ID)"
              echo "IP: $(sudo docker inspect --format '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $CONTAINER_ID)"
            done
            
            echo "Checking if nginx is listening on port 80:"
            sudo netstat -tulpn | grep :80
          ENDSSH

          # Then try to access it from GitHub runner
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "Attempt $ATTEMPT of $MAX_ATTEMPTS..."
            if curl -s -f -m 10 -L "http://$IP_ADDRESS"; then
              echo "Frontend is available!"
              echo "frontend_available=true" >> $GITHUB_OUTPUT
              break
            else
              echo "Frontend not available yet, waiting..."
              sleep 15
              ATTEMPT=$((ATTEMPT+1))
            fi
          done

          if [ $ATTEMPT -gt $MAX_ATTEMPTS ]; then
            echo "Frontend health check failed after $MAX_ATTEMPTS attempts"
            echo "frontend_available=false" >> $GITHUB_OUTPUT
            
            # Add additional diagnostics
            echo "Running diagnostics on the server..."
            ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP_ADDRESS << 'ENDSSH'
              echo "Checking Docker container logs:"
              sudo docker-compose -f ~/pokedex-app/docker-compose.yml logs --tail=50 frontend
              
              echo "Checking Nginx config inside container:"
              FRONTEND_CONTAINER=$(sudo docker ps -q -f name=frontend)
              if [ ! -z "$FRONTEND_CONTAINER" ]; then
                sudo docker exec $FRONTEND_CONTAINER cat /etc/nginx/conf.d/default.conf
              else
                echo "Frontend container not found"
              fi
              
              echo "Checking server firewall status:"
              sudo ufw status
            ENDSSH
          fi

      - name: Check backend API availability
        id: backend-health
        run: |
          # Get IP address from file
          IP_ADDRESS=$(cat ~/.ssh/instance_ip)

          echo "Checking backend API at http://$IP_ADDRESS:3000/admin/"
          MAX_ATTEMPTS=10
          ATTEMPT=1

          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "Attempt $ATTEMPT of $MAX_ATTEMPTS..."
            if curl -s -f -m 10 "http://$IP_ADDRESS:3000/admin/"; then
              echo "Backend API is available!"
              echo "backend_available=true" >> $GITHUB_OUTPUT
              break
            else
              echo "Backend API not available yet, waiting..."
              sleep 15
              ATTEMPT=$((ATTEMPT+1))
            fi
          done

          if [ $ATTEMPT -gt $MAX_ATTEMPTS ]; then
            echo "Backend API health check failed after $MAX_ATTEMPTS attempts"
            echo "backend_available=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up monitoring
        run: |
          # Get IP address from file
          IP_ADDRESS=$(cat ~/.ssh/instance_ip)

          echo "Setting up monitoring on the server..."
          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP_ADDRESS '
            # Check if node exporter is installed
            if ! command -v prometheus-node-exporter &> /dev/null; then
              # Install monitoring tools
              sudo apt-get update
              sudo apt-get install -y prometheus-node-exporter
              
              # Start monitoring services
              sudo systemctl enable prometheus-node-exporter
              sudo systemctl start prometheus-node-exporter
              
              echo "Monitoring tools installed and started"
            else
              echo "Monitoring tools already installed"
            fi
            
            # Verify monitoring service is running
            if systemctl is-active --quiet prometheus-node-exporter; then
              echo "Monitoring service is running"
            else
              echo "Monitoring service is not running, attempting to start..."
              sudo systemctl start prometheus-node-exporter
            fi
          '
        continue-on-error: true

      - name: Check Docker container status
        run: |
          # Get IP address from file
          IP_ADDRESS=$(cat ~/.ssh/instance_ip)

          ssh -i ~/.ssh/terraform-ec2 -o StrictHostKeyChecking=no ubuntu@$IP_ADDRESS '
            echo "Docker container status:"
            sudo docker ps -a
            
            echo "Docker Compose status:"
            cd ~/pokedex-app
            sudo docker-compose ps
            
            echo "Container logs:"
            sudo docker-compose logs --tail=50
          '
        continue-on-error: true

      - name: Generate deployment report
        run: |
          # Get IP address from file
          IP_ADDRESS=$(cat ~/.ssh/instance_ip)

          FRONTEND_STATUS="${{ steps.frontend-health.outputs.frontend_available }}"
          BACKEND_STATUS="${{ steps.backend-health.outputs.backend_available }}"

          echo "Frontend health check: $FRONTEND_STATUS"
          echo "Backend health check: $BACKEND_STATUS"

          if [ "$FRONTEND_STATUS" == "true" ] || [ "$BACKEND_STATUS" == "true" ]; then
            echo "deployment_success=true" >> $GITHUB_OUTPUT
            echo "Deployment completed successfully!"
            echo "Application URL: http://$IP_ADDRESS"
            echo "Backend API URL: http://$IP_ADDRESS:3000"
          else
            echo "deployment_success=false" >> $GITHUB_OUTPUT
            echo "Warning: Deployment health checks failed or partially failed."
            echo "Application URL: http://$IP_ADDRESS"
            echo "Backend API URL: http://$IP_ADDRESS:3000"
            echo "Please check the logs for more information."
          fi
